{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d6399-108f-4f0c-8eb5-36ee2e852439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "import numpy as npcm\n",
    "from requests.exceptions import Timeout\n",
    "\n",
    "all = pd.read_csv(\"all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abef7fa-851f-433c-bc0a-fcbf4d225ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Returns the content of the link while still being secure as some of the links may be malicious\n",
    "def get_content(link):\n",
    "    #print(link)\n",
    "    try:\n",
    "        response = requests.get(link, timeout=2)\n",
    "        if response.status_code == 200:\n",
    "            soupContent = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "        #print (soupContent)\n",
    "            str =' '.join([text.get_text() for text in soupContent.find_all(['h1', 'h2', 'h3', 'p'])])\n",
    "            if str ==\"\":\n",
    "                return None\n",
    "            print (\"found\")\n",
    "            return str\n",
    "        else:\n",
    "            #print(\"not ok\", response.status_code)\n",
    "            return None\n",
    "    \n",
    "    except Timeout:\n",
    "        #print(\"Request timed out!\")\n",
    "        return None\n",
    "    \n",
    "    except Exception:\n",
    "        # print(Exception)\n",
    "        return None\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_length = tokenizer.model_max_length\n",
    "\n",
    "\n",
    "\n",
    "# Tokenizes the text using a pretrained BERT tokenizer\n",
    "def tokenize_text(text):\n",
    "    # Truncate the input text to fit within the maximum sequence length\n",
    "    truncated_text = text[:max_length]\n",
    "    tokens = tokenizer(truncated_text, truncation=True,\n",
    "                    max_length=max_length, padding='max_length',\n",
    "                    return_tensors='pt')\n",
    "    return tokens\n",
    "\n",
    "# Read the CSV file\n",
    "# data = all.iloc[47000:50000]\n",
    "data = all.iloc[0:300]\n",
    "\n",
    "print(\"Done reading\")\n",
    "\n",
    "# Get the content for each URL and store it in a new column\n",
    "data['content'] = data['URL'].apply(get_content)\n",
    "print(\"Done applying links\")\n",
    "\n",
    "# Remove rows where content is None and their corresponding spam values\n",
    "data = data.dropna(subset=['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e275800-dbe6-41c4-909f-f912a786d19f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data\n",
    "\n",
    "\n",
    "# b = pd.read_csv(\"df_full of 1.csv\")\n",
    "# b = pd.concat([b, data], axis=0)\n",
    "data.to_csv(\"df_full of 1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc87369-c344-454d-af98-369753147be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spams = pd.read_csv(\"df_full of AAAA.csv\")\n",
    "db = pd.concat([spams, data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a2b8f-0874-4b4d-b42f-1e98b4ba2205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"urlCont.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91083047-4da6-4171-8b84-62d48852bd6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Done applying links\")\n",
    "\n",
    "# Remove rows where content is None and their corresponding spam values\n",
    "data = db.dropna(subset=['content'])\n",
    "\n",
    "# Tokenize the content and store it in a new column\n",
    "data['tokens'] = data['content'].apply(tokenize_text)\n",
    "\n",
    "print(\"Done tokenizing\")\n",
    "\n",
    "# Convert tokens to a string\n",
    "data['tokens_str'] = data['tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(data['tokens_str'])\n",
    "X = data['tokens_str']\n",
    "labels = data['spam']\n",
    "\n",
    "# Trains a logistic regression model using 10-fold cross-validation\n",
    "nSplit = 5\n",
    "kfold = KFold(n_splits=nSplit, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069db1ab-859d-4607-8011-83cf9969cd28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data['content'].values\n",
    "Y = data['spam'].values\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7, max_features=1000)\n",
    "vectorizer.fit(data['content'].values)\n",
    "X = vectorizer.transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state=7)\n",
    "Y_train = [int(numeric_string) for numeric_string in Y_train]\n",
    "Y_test = [int(numeric_string) for numeric_string in Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14376bf8-a340-450f-8a8b-acc7c9702352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_sample_weight(\"balanced\", Y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "clf = LogisticRegression(max_iter=5000, class_weight=class_weights)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "#testing\n",
    "prediction2 = clf.predict(X_test)\n",
    "score = metrics.accuracy_score(Y_test, prediction2)\n",
    "\n",
    "cm1 = metrics.confusion_matrix(Y_test, prediction2)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print (\"accuracy_scores\" ,accuracy_score(Y_test, prediction2))\n",
    "print (\"precision_scores\", precision_score(Y_test, prediction2, pos_label=1))\n",
    "print (\"recall_scores\", recall_score(Y_test, prediction2, pos_label=1))\n",
    "print (\"f1_scores\", f1_score(Y_test, prediction2, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90fcf3a-2d4f-4529-88d6-f6032f81b22a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('linkContentClassifier.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e5eeb-2ca0-4133-9daf-15895f282714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "accuracyScores = []\n",
    "f1Scores = []\n",
    "precisionScores = []\n",
    "recallScores = []\n",
    "\n",
    "i = 0\n",
    "for train, test in kfold.split(X):\n",
    "    print(f\"testing fold {i}\")\n",
    "    i += 1\n",
    "    trainX, testX = X[train], X[test]\n",
    "    trainY, testY = labels.iloc[train], labels.iloc[test]\n",
    "    print(trainX)\n",
    "    model = LogisticRegression(max_iter=5000, random_state=42)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    yPredictions = model.predict(testX)\n",
    "    curAccuracy = metrics.accuracy_score(testY, yPredictions)\n",
    "    curF1 = metrics.f1_score(testY, yPredictions)\n",
    "    curPrecision = metrics.precision_score(testY, yPredictions)\n",
    "    curRecall = metrics.recall_score(testY, yPredictions)\n",
    "\n",
    "    accuracyScores.append(curAccuracy)\n",
    "    f1Scores.append(curF1)\n",
    "    precisionScores.append(curPrecision)\n",
    "    recallScores.append(curRecall)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Uses metrics module to print the average accuracy of the model\n",
    "print('Average accuracy: ', sum(accuracyScores) / len(accuracyScores))\n",
    "print('Average F1 score: ', sum(f1Scores) / len(f1Scores))\n",
    "print('Average precision: ', sum(precisionScores) / len(precisionScores))\n",
    "print('Average recall: ', sum(recallScores) / len(recallScores))\n",
    "\n",
    "# save the model locally\n",
    "pickle.dump(model, open('linkContentClassifier.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ca29b-6c78-4b88-ab98-f9e3d97d0773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
